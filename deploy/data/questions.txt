!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
1
http://seqanswers.com/forums/archive/index.php/t-84823.html
View Full Version : metrics on BAM file
Moip
09-26-2018, 10:13 AM
Hi everyone,
I am doing exome sequencing, paired end, but not used to analyze reads.
After alignement, how do i proceed the BAM file?
Thank you
Richard Finney
09-26-2018, 04:19 PM
How many samples do you have?
How did you align the reads?
Are they tumor and normal samples?
Are looking for germline characteristics or somatic changes?
Moip
09-26-2018, 11:54 PM
I have three normal samples and looking for germline characteristics.
Mapping with %%BWA-MEM%%.
Thank you for you help Richard
Richard Finney
09-27-2018, 06:20 AM
You will probably want to do some variant calling on the bam files. This may include SNPS, fusions, amplification or deletions.

There are many tools to do this. Searching for these tools is straightforward:

https://www.google.com/search?q=germline+variant+calling+on+bam+files

You may want to use favorite, known tools already used at your organization, so ask around. A new tool may require some non-trivial installation.
Moip
09-27-2018, 06:48 AM
Thank you for you reply.
i need to understand some details, once i have a BAM file, before variant calling i have to remove duplicate, recalibrate BAM? run other metrics ?
sorry i am completely new to this.
Richard Finney
09-27-2018, 04:01 PM
You could do some quality checks and remove duplicates and recalibrate; but if you are just starting off, just go ahead and assume the data is good and try and see if you can get a report on variations using a commonly used tool. After you get that working, you can check out the other stuff and re-run a new workflow. Order of importance would be : QC, duplicate removal or marking , then re calibration. Many here at work say recalibration is not worth the effort. Theoretically marking or removing duplicates may be important upstream to a variant caller, and again, theoretically a variant caller could do that work for you so read the docs for your tools and follow their advice.

Do try and run a QC tool on your fastqs early.
Absolute easiest QC on bam files is "%%samtools%% flagstat" (google it).
Study the results and see if you can make sense of them.
Moip
09-27-2018, 11:12 PM
Thank you, i ll give a try. Do i ignore UMi for this analysis?
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2
http://seqanswers.com/forums/archive/index.php/t-84822.html
View Full Version : Adaper sequence to Read fastq
CarnifexRex
09-26-2018, 09:08 AM
Hello,

Fairly new to bioinformatics and first time posting, hopefully I sound halfway intelligent

My FASTQs contain adapter sequences in the read name. This adapter sequence includes a UMI. However my postprocessing software requires the UMI to be part of the read. Is there some way of inserting the adapter sequence from the read name to the beginning of the read? I'm guessing I'll also need to insert some bogus quality scores as well.

To visualize, I need to turn this:
@M01179:478:000000000-C33YY:1:1101:17276:1520 2:N:0:CTTGTATGTATG
TTGTCGTTCCTTTCTTTTTGTCTCTTTCCTGTACCTCTAG
+
11111333@B1B11AA3A3B1A3B3BFEE333130110A0

into this:

@M01179:478:000000000-C33YY:1:1101:17276:1520 2:N:0:CTTGTATGTATG
CTTGTATGTATGTTGTCGTTCCTTTCTTTTTGTCTCTTTCCTGTACCTCTAG
+
AAAAAAAAAAAA11111333@B1B11AA3A3B1A3B3BFEE333130110A0

This would need to be a scriptable solution, and work on all reads from a High Out-put NextSeq run

Thanks in advance
GenoMax
09-26-2018, 11:01 AM
Are you sure about that? Generally in case of Illumina sequencing index sequences (which are not part of actual reads) are transferred to the fastq header as a part of demultiplexing process. That is what you are probably seeing e.g. "CTTGTATGTATG".
CarnifexRex
09-26-2018, 11:11 AM
That is correct, sequence CTTGTATGTATG is my index sequence. The first 6 bp (CTTGTA) is my sample barcode, the second 6 bp (TGTATG) is a molecular barcode. This second sequence is random, so changes across every read.

I need to add the entire 12 bp sequence to the beginning of my read in order to utilize the UMI portion of the adapter in my alignment and variant calling software.
GenoMax
09-27-2018, 04:23 AM
This may be easier to do by obtaining the index read as a separate fastq file. You will also get real Q-scores for bases in index read when you do that. Stand-alone bcl2fastq allows one to get data in this format. I assume you may be able to do this using BaseSpace as well, if that is what you are using.

You can then use a program called "%%Seqkit%%" (https://bioinf.shenwei.me/seqkit/usage/#seqkit) (and specifically option "seqkit concat" to concatenate your index read in front of the actual read).
CarnifexRex
10-03-2018, 09:19 AM
Thats fantastic. This confirms by believe that there's a tool for everything.

This does exactly what I need, with one exception. It calls the entire FastQ into memory, which is a problem when the FastQ files are 20GB each.

I thought faidx indexing might help, but 1) bcl2fastq outputs gzip not bgzip files, and 2) my input files are FastQ and not FastA. I also thought of trying to stream the job by just providing a list of read names to concatenate using the seqkit common or grep command, but I couldn't get that to work.

Now I'm thinking of some combination of sort, split and bash loop but I'm still a novice at linux scripting.

Does anyone have some suggestions on how to process large files using seqkit?

Thanks
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
3
http://seqanswers.com/forums/archive/index.php/t-84440.html
View Full Version : What is the best program for MSA of 33 very similar sequences 113 00 bp long?
kajsa
09-06-2018, 01:07 AM
Hello,

I want to do a multiple sequence alignment with 33 sequences that are 99,99% similar and are around 113000 bp long.

I have looked around and found %%MAFFT%% and %%MAUVE%%. Are there any other programs to use that I've missed?

Thankful for any advise.
Kajsa
colindaven
09-13-2018, 03:17 AM
Muscle might be good. MUGSY is probably excellent for this use case given the length of the sequence.

cheers
Colin
kajsa
09-13-2018, 04:13 AM
%%Muscle%% might be good. %%MUGSY%% is probably excellent for this use case given the length of the sequence.

cheers
Colin
Thanks a lot!
Kajsa
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
4
http://seqanswers.com/forums/archive/index.php/t-84275.html
View Full Version : Differential Expression Analysis
DeDeoxys
08-27-2018, 08:54 PM
I am working with novel RNAseq data from a type of grass whose genome has not yet been completely sequenced or annotated. I have a number of FASTQ files with RNAseq data from different parts of the plant and am trying to conduct a differential expression analysis of these files. I was planning to use the DEGseq package in R to conduct the analysis, but from what I understand, this requires me to map the reads to an index to ultimately convert them to the .bed format and I would also need a reference genome file in the ucsc refFlat format. Since this plant genome has not even been sequenced, these files are unavailable, so I thought to map the reads to the genome of brachypodium distachyon, which is a model organism for grasses. I was able to create an index through bowtie using the genome from phytozome, but I have not been able to find a reference file for brachypodium in the reFlat or GTF format. Is there any way to convert to or create a reference file in the GTF or refFlat format, and am I even on the right track to conduct differential expression analysis on these files?
I also have access to the original RNA assembly data which came from an illumina HiSeq. I'm not sure if this would be helpful.
ASintsova
08-31-2018, 06:23 AM
I don't know much about plants, but it sounds like you might want to try to build de novo transcriptome assembly - https://www.sciencedirect.com/science/article/pii/S2214662817301032
gringer
09-04-2018, 02:43 AM
Use supertranscripts as your reference genome:

https://github.com/Oshlack/Lace/wiki

https://github.com/trinityrnaseq/trinityrnaseq/wiki/SuperTranscripts
%%Lace%%
%%trinityrnaseq%%
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
5
http://seqanswers.com/forums/showthread.php?t=84135
View Full Version : quantifying transcripts in a redundant genome
garlic
08-21-2018, 09:34 PM
Hi,

I am trying to quantify the number of reads mapping to genes in a highly redundant bacterial genome (i.e., often several exact gene copies in the genome).

I've mapped reads to genes with %%bbmap%%, and quantified using featurecounts. My problem is that reads are only counted for one of the copies of redundant genes, and not all of them.

I just want to count the number of expressed genes (I want to count all of the copies since I can't distinguish them). I've tried playing around with multi-mapping parameters in featurecounts, but nothing has changed.

Does anyone here know how to do this?

Thanks!
ASintsova
08-31-2018, 06:50 AM
You would have to play with your aligner (%%bbmap%%). I've never used that one before, but other aligners like %%bowtie2%% and %%BWA%% have an option to search for multiple alignments and report all. However, if you do this, you will be overestimating expression of your redundant genes.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
6
http://seqanswers.com/forums/archive/index.php/t-83988.html
View Full Version : CpG sites in Bismark
Hedi86
08-13-2018, 11:21 PM
Hello

im trying to calculate the percentage of covered CpG sites in my RRBS library and compare it with total CpG sites in reference genome. i got splitting report from Bismark (see bellow)

q1- could i say CpG sites in my RRBS library are equal to number of Total methylated C's in CpG context + number of Total C to T conversions in CpG context (around 19 million) ? if No how i can find total CpG sites in RRBS library?

q2- i downloaded pig CGI annotation and counted all CpG sites but the total was around 2 million. sound very low for me. how i can find the actual number of CpG sites in reference genome?

q3- is there a way to determine CpG sites per chromosome and compare it with CpG sites in each chromosome of reference genome?


Final Cytosine Methylation Report
=================================
Total number of C's analysed: 141645338

Total methylated C's in CpG context: 7904886
Total methylated C's in CHG context: 50683
Total methylated C's in CHH context: 107717

Total C to T conversions in CpG context: 12298571
Total C to T conversions in CHG context: 35912924
Total C to T conversions in CHH context: 85370557
fkrueger
08-14-2018, 03:03 AM
Hi Hedi,

q1- could i say CpG sites in my RRBS library are equal to number of Total methylated C's in CpG context + number of Total C to T conversions in CpG context (around 19 million) ? if No how i can find total CpG sites in RRBS library?

No, I'm afraid you can’t say that. The numbers reported are the overall numbers of methylation calls performed for the entire run, and have nothing to do with the number of genomic positions covered. If you want to find out how many Cs were covered in your experiment you generate a coverage file where each line corresponds to a covered C position. So the number of lines in the file (zcat file.cov.gz | wc -l) is the number of positions covered in your experiment.

q2- i downloaded pig CGI annotation and counted all CpG sites but the total was around 2 million. sound very low for me. how i can find the actual number of CpG sites in reference genome?

You could use %%bam2nuc%% (part of %%Bismark%%) to find out the number of Cs, or CpGs, in the genome. Here is the output for the Sscrofa11.1 build (genome-wide).

A 717891230
AA 237125812
AC 124343360
AG 171421615
AT 185000140
C 517402066
CA 178358877
CC 136906913
CG 30619972
CT 171516061
G 517706165
GA 147162051
GC 108922386
GG 136983938
GT 124637555
T 719048243
TA 155244114
TC 147229152
TG 178680414
TT 237894187

CGIs are only a small, albeit CG-rich, fraction of the genome, so 2M doesn’t sound too bad.


q3- is there a way to determine CpG sites per chromosome and compare it with CpG sites in each chromosome of reference genome?

I would suggest you use %%SeqMonk%% for this kind of work. You need to keep in mind though that RRBS only expects to cover ~1-2% of the genome at very specific positions, so getting an idea about how many CpG were covered per chromosome is almost certainly not anything you should be interested in.
Hedi86
08-15-2018, 02:27 AM
thank you for your advice and help. in %%methylkit%% using following command you can get coverage as well. but im wondering is it CpG coverage or read coverage? they used both definitions in their tutorial (https://www.bioconductor.org/packages/3.7/bioc/vignettes/methylKit/inst/doc/methylKit.html#24_descriptive_statistics_on_samples) . is it different with your suggested way of CpG coverage calculation?

getCoverageStats(my.methRaw[[1]],plot = F,both.strands = FALSE)
read coverage statistics per base
summary:
Min. 1st Qu. Median Mean 3rd Qu. Max.
10.00 12.00 15.00 28.25 20.00 131376.00

thanks again
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
7
http://seqanswers.com/forums/archive/index.php/t-83933.html
View Full Version : Split Fastq into 2 files
landrjos
08-09-2018, 12:52 PM
Hi All,

I have a fastq file which I would like to split into 2 files with every other read going into the 2 separate files. What would the Split function command line be for this? I am a new to computing, so it you are most explicit that would be helpful.

Best,
anoopkmr
08-09-2018, 06:57 PM
Found it in a post here:https://stackoverflow.com/questions/21309020/remove-odd-or-even-lines-from-a-text-file

"sed
You can accomplish the same thing with sed. devnulls answer shows how to do it with GNU sed. Below are alternatives for versions of sed that do not have the ~ operator:

keep odd lines

sed 'n; d' infile > outfile
keep even lines

sed '1d; n; d' infile > outfile"
landrjos
08-09-2018, 07:31 PM
Hi anoopkmr,

Thanks for the reply. I made a mistake, I was not clear enough. I would like to partition the odd or even "reads" from a fastq file. The reads are in groups of 4 lines in the fastq file. So I would like read 1 (lines 1-4) to go to file1, and read 2 (lines 5-8) to go to file2, and so on until the whole fastq file is divided into two files, the odd (lines 1-4, 9-12, etc...) output file and the even (lines 5-8, 13-16, etc...) output file.

Not every even line and every odd line going to the output files.

Is there a way to do that?

Best,
anoopkmr
08-09-2018, 07:55 PM
That makes a lot more sense. Sorry, in my own confusion I thought you were trying something more creative and beyond my understanding.

%%fastq-dump%% seems like an option but if you are generating these files from BAMs it might be easier to step back to the previous step and generate them all at once.

Not very useful but I hope it helps. Good luck!
GenoMax
08-10-2018, 04:00 AM
@landrjos: What you are describing is called an interleaved fastq file where R1 and R2 reads are present in a single file.

You can use reformat.sh from %%BBMap%% suite (https://sourceforge.net/projects/bbmap/) to separate the R1 and R2 reads into their own files.

reformat.sh in=interleaved.fq.gz out1=R1.fq.gz out2=R2.fq.gz
lethalfang
09-27-2018, 10:31 PM
Try this:
cat original.fastq | awk 'NR%8==1 || NR%8==2 || NR%8==3 || NR%8==4' > first4s.fastq
cat original.fastq | awk 'NR%8==5 || NR%8==6 || NR%8==7 || NR%8==0' > second4s.fastq

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
8
http://seqanswers.com/forums/archive/index.php/t-83862.html
View Full Version : How to get a report like stuff of a bam file how many percent of the exons are cover
Dear Collegues,

Lets say I have a miseq run and have the .bam file from the squencer and I would like to know how many percent of the exons (specific genes) are coverred in these .bam files?

Is it possible?

Thanks in advance
Gopo
08-07-2018, 02:58 AM
Try CollectHSmetrics - part of %%Picard%% Tools
For details see:
https://broadinstitute.github.io/picard/command-line-overview.html
mhmtgenc
08-07-2018, 03:22 AM
Try CollectHSmetrics - part of Picard Tools
For details see:
https://broadinstitute.github.io/picard/command-line-overview.html

So how coul I be able to get a BED file or prepare it by myself? Could you give me a clue or a tutorial of this. Cause I have trouble on this. I know this is hard to expalin it here but can I get any file or manual for this?
Gopo
08-08-2018, 10:11 PM
You will have to make the BED file yourself. Here is a guide:


# install picard
cd ~/bin/
wget https://github.com/broadinstitute/picard/releases/download/2.18.10/picard.jar
mv picard.jar picard-2.18.10.jar

# index reference (Reference is AmexG_v3.0.0.fa)
samtools faidx AmexG_v3.0.0.fa

# create sequence dictionary
java -Xmx64g -jar ~/bin/picard-2.18.10.jar CreateSequenceDictionary \
R=AmexG_v3.0.0.fa \
O=AmexG_v3.0.0.dict

# Convert BED to interval list
java -jar ~/bin/picard-2.18.10.jar BedToIntervalList \
I=rfs.immunome.bed \
O=rfs.immunome.interval.list \
SD=AmexG_v3.0.0.dict

# run CollectHsMetrics
java -Xmx64g -jar ~/bin/picard-2.18.10.jar CollectHsMetrics \
BAIT_INTERVALS=/ssdwork/jelber2/rfs/rfs.immunome.interval.list \
BAIT_SET_NAME=Immunome \
TARGET_INTERVALS=/ssdwork/jelber2/rfs/rfs.immunome.interval.list \
METRIC_ACCUMULATION_LEVEL=SAMPLE \
R=/ssdwork/jelber2/rfs/AmexG_v3.0.0.fa \
I=ALL-samples.bam \
O=ALL-samples-coverage-metrics.txt

# if needed, add readgroups
java -Xmx64g -jar ~/bin/picard.jar AddOrReplaceReadGroups \
I=ALL-samples.bam \
O=ALL-samples-RG.bam \
SORT_ORDER=coordinate \
RGPL=illumina \
RGPU=barcode \
RGLB=Lib1 \
RGID=all \
RGSM=all \
VALIDATION_STRINGENCY=LENIENT

# run CollectHsMetrics with ReadGroups added to BAM
java -Xmx64g -jar ~/bin/picard-2.18.10.jar CollectHsMetrics \
BAIT_INTERVALS=/ssdwork/jelber2/rfs/rfs.immunome.interval.list \
BAIT_SET_NAME=Immunome \
TARGET_INTERVALS=/ssdwork/jelber2/rfs/rfs.immunome.interval.list \
METRIC_ACCUMULATION_LEVEL=SAMPLE \
R=/ssdwork/jelber2/rfs/AmexG_v3.0.0.fa \
I=ALL-samples-RG.bam \
O=ALL-samples-coverage-metrics.txt


Best,
Gopo
anoopkmr
08-11-2018, 05:48 PM
This tools helps me create bed files from a gene list:
https://genome-euro.ucsc.edu/cgi-bin/hgTables

Choose bed format while downloading.
%%hgTables%%
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
9
http://seqanswers.com/forums/archive/index.php/t-83723.html
View Full Version : Demultiplexing FASTQ with custom indices
bpbbentley
07-31-2018, 01:50 AM
Hi all,

I'm fairly new to the realm of bioinformatics with large data sets, so apologies if I've missed something crucial here...

I've recently received some Illumina HiSeq2500 data in FASTQ format which haven't been demultiplexed. We've used custom i5 and i7 sequences in unique combinations for 96 samples. I was given the data in 8 FASTQ files, 2 per lane (4 lanes) with paired-ends. I've concatenated all of the forward and all of the reverse reads into 2 files for simplicity. I've been using the demuxbyname.sh method through %%BBMap%% - but I keep running into a couple of problems:

1. When I run demuxbyname.sh with a single string I only receive ~2500 reads in the output files. I've noticed that a lot of the index sequences in the FASTQ files contain N's - especially as the first base call (for i5 and i7).

2. This generally takes ~3hrs, but when I then attempt to run the script with an index.txt file containing multiple index combinations, the compute time increases exponentially.

Any help on either of these points is greatly appreciated!
GenoMax
07-31-2018, 03:29 AM
Before we get into specifics can you ask your sequence provider to do this demultiplexing with Illumina's program called bcl2fastq (you can't do this since it requires access to the full data folder for the flowcell). That should be trivial for them to do (and they should have done it in first place unless you chose not to give them the sample_ID_index combinations).

Can you tell us how you are running "demuxbyname.sh" (full command line)? You should run it like this: https://www.biostars.org/p/139395/#139409 You could start multiple runs (even 96 with just one index combo) to speed things up.

There is also another package called %%deML%% (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4341068/)that can be used for this.
liorgalanti
07-31-2018, 07:18 PM
https://biosails.github.io/pheniqs/ 
%%pheniqs%%
bpbbentley
08-02-2018, 09:15 PM
Thanks for your feedback on this, it's much appreciated!

I've contacted BGI and they've said that they'll help me with the demultiplexing. I thought it was strange that they simply provided FASTQ files for each lane, especially as they contacted me early on and asked me to provide the index sequences...

I've run the command a few ways, this is ideally what I'm going for:

../sw/bbmap/demuxbyname.sh in=all_lanes_1.fq in2=all_lanes_2.fq out=demux_out/%_1.fq out2=demux_out/%_2.fq prefixmode=f substringmode=f names=index_names_s1.txt

However, I have run it using single sequence strings, and also just running 1 lane of data at a time. Thanks again for your help.
GenoMax
08-03-2018, 05:16 AM
Your indexes most likely look like Index1+Index2 (e.g. GGACTCCT+GCGATCTA) then that is how you need to include them in the file one per line. Is that how you are doing this?
bpbbentley
08-05-2018, 08:57 PM
Yep my indexes are index1_index2 in the read header, and my .txt file reflects these. I get output files with the index complex names, but these are typically not populated with reads...
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
10
http://seqanswers.com/forums/archive/index.php/t-83663.html
View Full Version : depth of coverage and read depth using Bismark
Hedi86
07-26-2018, 10:36 PM
hello everyone

is it possible to calculate depth of coverage and read depth using %%Bismark%% ? if yes how and if No what is the best way to calculate depth of coverage and read of depth from RRBS reads taking from illumina sequencing ?

Best
fkrueger
07-27-2018, 01:40 AM
Bismark itself is merely the alignment tool, and as such does not do any further analysis. I am sure there are several different options to choose from to assess sequence coverage, I can only recommend %%SeqMonk%% which offers visualisation and calculations in one package.
Hedi86
07-30-2018, 01:58 AM
thank you for your help.

i tried to use seqmonk, but i wasnt sure which file should i import (.fq file after trimming or COV file from bismark) ? in addition what is the correct pipeline in seqmonk, is it ok to import>define probes>running window generator>quantitation>% coverage quantitation OR Coverage depth quantitation ? Seqmonk then report a summary but in summary report noting showing the coverage or Coverage depth.

thanks again
fkrueger
07-30-2018, 02:13 AM
It depends a little on which kind of statistics you are interested in. If you really just want to get a value for a fold-coverage of your experiment you should probably import the (deduplicated) Bismark BAM files into SeqMonk because this statistic is a function of the total read length of all reads in your experiment and the size of the genome.

If you import those BAM files you can do e.g. a running Window probe generation followed by a read count quantitation. If you then Click on "DataStore Summary Report" you will see a report that has - among many fields - a Fold Coverage column: this is the value you are looking for. You can also get a mean/median quantification for your probe of interest.

If you wanted to get similar statistic for single-base resolution cytosines you could import the coverage files, design probes over the Read Positions and count their abundance. But yea, it depends on what you really want to get out in the end.
Hedi86
07-30-2018, 02:58 AM
really appreciate your comment

so could we say that 0.04 as fold coverage is equal to 4X depth coverage, and could we say that read coverage is equal to mapping efficiency?

thanks again
fkrueger
07-30-2018, 03:07 AM
Not quite. A 0.04 fold-coverage means that - on average - each position in the genome was covered 0.04 times. A 4-fold would be, well, 4.

This value is obviously not so meaningful if you used only methylation calls to calculate the value, since they are only 1bp long ( (total number of reads * read length) / length of genome = fold-coverage).

The mapping efficiency is a mapping specific parameter that has to do with which fraction of a sequencing file comes from mappable parts of the genome, and as such has nothing to do with fold-coverage. If you take a library with a 70% mapping efficiency and sequence four times as much, the fold coverage will be 4-times higher but the mapping efficiency is unchanged...
Hedi86
07-30-2018, 03:10 AM
thanks alot for your explanation, now became more clear :)
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
11
http://seqanswers.com/forums/archive/index.php/t-83194.html
View Full Version : How to add GFP sequence to mouse genome for mapping
Kaizen
06-29-2018, 04:47 AM
Hi guys,
I was wandering what is the right way to add the sequence of GFP reporter to a mouse genom. Basically instead of "geneA" in the genome the modified mouse has "geneA-IRES-GFP".
I guess that adding just the sequence of GFP as an extra chromosome is not ideal, since a read that would map to both "geneA" and "IRES-GFP" would not be mapped by STAR.
Does anyone know what to do?
Thanks
atpoint
07-11-2018, 01:37 PM
You could make an alternative genome by masking the exons of geneA in the fasta (so adding N instead of the actual sequence), and then add the transgene sequence as an extra chromosome.
Kaizen
09-12-2018, 05:46 AM
but in that case, if you have a read mapping both to the transgene sequence and to the sequence upstream of downstream of it would lead to incorrect mapping and therefore will be lost, right?
atpoint
09-12-2018, 05:50 AM
The read should be soft-clipped. Use %%BWA mem%% for alignment. Soft-clipping of reads is the basis of structural variant detection by many SV tools.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
12
http://seqanswers.com/forums/archive/index.php/t-83037.html
View Full Version : Tool for grouping sequences into clusters with homology within each above threshold
prishlyK
06-22-2018, 01:00 AM
Is there a tool/script/algorithm for grouping sequences into bins so that within each group homology for any two sequences is above (or equal to) a certain threshold value (unless there's only one sequence in a bin)? Some sequences may end up being chimeric, some bins may end up containing a single sequence but only if they don't fit into all other bins. Asked this on biostars, but got no replies.
GenoMax
06-22-2018, 03:02 AM
Take a look at %%CD-HIT%% (http://weizhongli-lab.org/cd-hit/).
prishlyK
10-09-2018, 02:12 AM
Thanks! Sorry for taking so long to reply. Great tool. It doesn't seem to allow filtering by target coverage or choosing a "centroid" sequence in a cluster, though
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
13
http://seqanswers.com/forums/archive/index.php/t-82781.html
View Full Version : Subsample regions of too high coverage
sbrohee
06-07-2018, 06:33 AM
Hi all,

Do you think there is an efficient way of downsampling only a few regions of a bam files (in my case the regions with a too high coverage).

The idea, would be too randomly remove reads in regions where the coverage is above a given coverage.

Indeed, in my analyses, those regions cause some steps of the pipeline to become really slow.

Thanks for all your suggestions...
sbrohee
06-08-2018, 02:12 AM
OK... I just ran into a great tool that seems to do exactly what I wanted. It is called %%VariantBam%% (https://github.com/walaj/VariantBam, https://www.ncbi.nlm.nih.gov/pubmed/27153727).

./variant highcoveragebam.bam -m maxcoverage -o reducedmaxcoveragebam.bam -b

I hope it will be useful for some of you.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
14
http://seqanswers.com/forums/archive/index.php/t-82714.html
View Full Version : Extract the XS field from bam
Yexzm
06-04-2018, 05:01 AM
Hello everyone,

BWA mem generates for each read an "XS" field (the suboptimal alignment score). When I use samtools view, it's presented this way :
- NS500801:90:HY7JVBGXY:2:21205:8003:11253 147 chrM 958 60 76M = 920 -114 CCCCCTCCCCAATAAAGCTAAAACTCACCTGAGTTGTAAAAAACTCCAGTTGACACAAAATAGACTACGAAAGTGG >>;@B@CC1C??=??AAC=???>C@C>CC@BAAA?@<>>>>>=B?BB@@@?A=B=B>>>><@A=B<=;A>=@=;>= BD:Z:IIIMPOLKNKJJJBIMOMIBBJLKKIKLMKJKJIIKHAAAAILKKKLJIHJKHHHH@@GGIHLLLKKLJCKOJLJJ PG:Z:MarkDuplicates RG:Z:id BI:Z:LLLPTSOOSROPQHOTSQOGGNPPQNQPROLPNMMNNFFFFLNNONPOMLNOMLMNEEKLNMOOPOONMHOROPNN NM:i:0 AS:i:76 XS:i:55

Does anyone know an easy way to extract it ? With R ? I mean I know I could use samtools view + awk but it'll take a long time.

Thanks in advance!
lindenb
06-04-2018, 05:51 AM
using %%bioalcidaejdk%%: http://lindenb.github.io/jvarkit/BioAlcidaeJdk.html


java -jar dist/bioalcidaejdk.jar -e 'stream().forEach(R->println(R.getAttribute("XS")));' in.bam
Yexzm
06-07-2018, 04:12 AM
Hi lindenb, thank you for your answer,

How can I get the read name too ? I would like to have a table the in the first column the read name, and in the second the XS.
lindenb
06-07-2018, 04:19 AM
> How can I get the read name too ?

... printl(R.getReadName()+" "+R.getAttribute("XS")
Yexzm
06-25-2018, 04:39 AM
Thank you very much for your help!

The output file is too big, I'm trying to get the chromosome too so that I can separate it per chromosome. I tried "getReferenceIndex" but it returns "null". Do you know how I could do ?
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
15
http://seqanswers.com/forums/archive/index.php/t-82315.html
View Full Version : best way to index tab-delimited text file
Joseph White
05-09-2018, 03:04 AM
What is the best way to index a tab-delimited text file containing chromosome, position and variant data? My files are huge and too big to maintain in memory, so indexing seems the only viable option.

jwhite
GenoMax
05-09-2018, 03:18 AM
%%tabix%% (http://www.htslib.org/doc/tabix.html)from Samtools.
Joseph White
05-09-2018, 05:50 AM
tabix (http://www.htslib.org/doc/tabix.html)from Samtools.

The file is not in BED, GFF, or SAM format.
GenoMax
05-09-2018, 06:00 AM
Tabix can accept these formats: -p gff|bed|sam|vcf
Joseph White
05-09-2018, 06:11 AM
Tabix can accept these formats: -p gff|bed|sam|vcf

Oh, that's right. All I have to do is add a third column of '.' to make it VCF. Thanks.
finswimmer
05-12-2018, 09:57 PM
Hello,

Tabix can accept these formats: -p gff|bed|sam|vcf

these are just presets. One can define in which column the chromosome (aka sequence name), begin and end position are located.

So if you have the chromosome name in the first column, the position (begin == end) in the second column you can index like this:

tabix -s1 -b2 -e2 my_file.gz

This way, tabix provide a way to index each tab delimited file, which have sorted positional data. Also one can define whether the position is 0-base or 1-based give the parameter "-0" if it's 0-base.

fin swimmer
sam657
05-13-2018, 02:24 AM
These methods are still working for you?
finswimmer
05-13-2018, 07:59 PM
These methods are still working for you?

Yes, why they shouldn't? It's a documented (http://www.htslib.org/doc/tabix.html) feature. The -p parameter is just a shorthand for this. So in the case above, it would also work to use "-p vcf" as the chromosome name is column 1 and the position in column two like it is in a vcf. About the other columns tabix don't care. It doesn't check whether it is a valid vcf file.

fin swimmer
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
16
http://seqanswers.com/forums/archive/index.php/t-82263.html
View Full Version : non-overlapping options please help!
matt_ms1
05-07-2018, 02:15 PM
Hello all,

Struggling with a 16s metagenomics research project using human fecal data. Have experience with QIIME and usearch, so not quite the first rodeo... couldn't get paired ends to align before realizing that the amplicon length was ~400, and sequencing provided 150bp read lengths. Oops!

Every paper I've read // project I've worked on has used paired-end reconstruction > open/close reference OTU selection. Faced with this new situation I'm at a loss for what tools to use.

Having a hard time what to do next. Does anyone have recommendations for what tools to look into? Eager to produce something for the PI, but hesitant to assume ~250bp of the amplicon length by just 'going for it' and filtering by PHRED > Closed reference OTU picking in QIIME... Any thoughts/advice/guidance would be greatly appreciated.
GenoMax
05-07-2018, 02:59 PM
Have you tried %%BBMerge%% to see if there are some reads that can merge (have insert sizes smaller than expected).

You could try bbmerge.sh's tadpole "extend "modes to see if you are able to assemble some of this data.
NGSMicro
05-08-2018, 12:32 AM
Have you tried %%QIIME2%%?

It provides a few higher resolution methods of clustering meaning you may be able to 'get away with' using only the forward reads.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
17
http://seqanswers.com/forums/archive/index.php/t-82099.html
View Full Version : much different result from shotgun metagenomics and 16S amplicon
chloe1005
04-27-2018, 06:20 AM
Hi, community,

I am analyzing the taxonomic profiling of my shotgun data. Which are 100bp paired-end reads from Illumina Hiseq. Now I am using Metaphlan2 to do the metagenomics profiling. However, the profiling result is far away from Illumina 16S miseq results. Since I have also been using Illumina 16S Miseq to test the taxonomy of my samples for several years. I have two the control samples and treatment samples. In Metaphlan2 results, it gave me around 30% archaea and 70% bacteria for control samples, while Miseq 16S reads tell me that only around 15% archaea and 85% bacteria for control samples. For treatment, shotgun profiling told me 60% archaea and 40% bacteria, while Miseq gave me 20% archaea and 80% bacteria. For my experience, this kind of sample could not achieve that much archaea abundance than bacteria. Furthermore, some(not all) bacteria and archaea composition are different between %%Miseq%% result and %%Metaphlan2%% result.

Why is the result so different? Are there any suggestions why the two method result differs so much?

I am confused. Looking forward to a help.
kbseah
05-11-2018, 06:39 AM
Hello,

I've seen similar issues with my own data, and in general I think that taxonomic profiles should always be taken with a pinch of salt. Off the top of my head, a few possibilities:

1. Metagenome read profiling methods can be quite sensitive to the database used and the cutoffs for assigning a given read to a taxon. It might be worth trying a different pipeline like %%Kraken%% (https://www.ncbi.nlm.nih.gov/pubmed/24580807) to see if you get similar results.

2. rRNA operon copy number can vary between different microbial species. E.g. if species A has two copies of the 16S gene per genome, and species B has only one, one, then A might appear to be twice as abundant as B. You could try profiling only the 16S sequences from the metagenomic shotgun libraries to see if this gives a better fit to your amplicon libraries, e.g. with %%Emirge%% (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3219967/) or %%Matam%% (https://www.ncbi.nlm.nih.gov/pubmed/29040406). My colleagues and I are working on a pipeline for quick screening and comparison of metagenome libraries for SSU using Emirge and other tools (https://github.com/HRGV/phyloFlash). %%phyloFlash%%

3. Amplicon libraries can be quite heavily influenced by amplification and primer biases during PCR (e.g. see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3592464/)

Hope this helps!

-- Brandon
chloe1005
05-11-2018, 07:49 AM
Hi,
Thanks so much for the reply. These make sense to me. And now I am totally agreed. During these days after I posted the thread, I have been trying many different method and software. I found just taxonomic profiling cannot be accurate, and the different result got from the comparison between 16S amplicon is expectable.
Kraken gives me 2% reads hit NCBI. It is lucky to meet PhyloFALSH, which can be used for extract 16S reads and give me the taxonomy result. 0.107% reads hits to SILVA database. Still waiting for the publication of PhyloFLASH.
I have also tried a software- Kaiju, which got 47% reads hits to NCBI nr database, 31% reads hits in RefSeq Complete Genomes database, 38% reads hits in proGenomes database.
Interesting, challenging but confusing. Maybe for environmental samples, assemble is necessary.
Looking forward to more suggestions shared from you.
Best.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
18
http://seqanswers.com/forums/archive/index.php/t-81918.html
View Full Version : suitable aligner for human RNA-seq
yueli
04-19-2018, 06:42 AM
Hello,

Human RNA-seq dataset was generated from Illumina HiSeq 3000 with 2X100 cycles run.

The first step is making alignment of the reads to the human genome. These are many aligner, such as: %%Bowtie%%, %%GASSST%%, %%PASS%%, %%SOAP%%, %%BOAT%%. Each aligners has different performs in different kinds of data.

Which is the best suitable aligner for RNA-seq data?

Thank you in advance for great help!

Sincerely,

Yue
colindaven
05-02-2018, 04:01 AM
%%STAR%% or %%Hisat2%%, and NOT Tophat2
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
19
http://seqanswers.com/forums/archive/index.php/t-81897.html
View Full Version : Need simple way to get coverage per 10kb interval on reference
jmartin
04-18-2018, 02:15 PM
Is there a tool that can tell me coverage per some uniform interval along a set of reference contigs? I know I could use %%bedtools%% coverage and build a bed file defining the intervals, but I was asked if there wasn't already a tool that could just do uniform intervals on its own without having to setup a bedfile to define the intervals.
GenoMax
04-19-2018, 04:19 AM
Use %%mosdepth%% (https://github.com/brentp/mosdepth)and option --by 10000.

You can also use %%deepTools%% (https://deeptools.readthedocs.io/en/develop/)and option multiBamSummary bins.
Mizzou55
04-19-2018, 10:36 AM
Does the --by option sum up the coverage for an interval (10000), or does it provide the depth at each interval?
jmartin
04-19-2018, 01:19 PM
Thanks for the suggestion, mosdepth is just what I need!

@Mizzou55 it looks like its reporting the average depth across the requested intervals. If you want depths at specific positions in your reference I guess you'd have to setup a bed file with the positions you want reported
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
20
http://seqanswers.com/forums/archive/index.php/t-81825.html
View Full Version : Pipeline construction (metagenomics 101)
sbW
04-14-2018, 07:21 AM
Hello guys / gals,
I really feel that this might be one of the last options and almost a cry for help, I've been reading and studying metagenomics field for over a month now, and I still have a not properly understood the concepts of it. If you would help me or guide me in any way into a general direction of better understanding it i would be extremely grateful.

So here is the problem, I am a master student who's new to bioinformatics field (had only 1 lecture of it) and now I am assigned to make a pipeline for metagenomic analysis. There are some main ideas that are expected of me, and I've been reading literature on it, but I find it really hard to review this literature as I do not fully understand them and also I have never written a thing like that.

So the objective is to propose a pipeline, in which sampled data would be placed into phylogenetic trees to see who is in the sample in reference to some refence database. The input is FASTA files from metagenomic bins ( there's a pipeline for sorting them into contigs, filtering , quality control and etc. ) which is expected to be a single genome in a single bin. From this place I should take over and suggest tools for further data processing. The steps in my pipeline should be:

1) Selecting Marker genes
2) Indentifying them in the bins
3) Allignment processing
4) Concatenation of marker genes
5) Applyig evolutionary models and
6) infering phylogenetic trees.


So here goes some questions about it, and sorry if the answers are obvious to you (because they are not for me..) :

I've seen in literature that %%Amphora%%(2) and %%Phylophlan%% are the methods using concatenated marker gene phylogeny, but others (most that i found) use OTUs that seem to be used as the same thing, is there a difference between them?

I try to refer to the literature I am reading, but there is too much variation and I do not feel confident that they are answering the same questions I should be. Is there any good/ working pipelines that are working on the same or similar protocol that i described?

How should i choose the reference genomes and reference marker genes, as I cannot see any correlation between different literature, maybe you have any information where I could read it up?

If you have any comprehensive literature that might be helpful on any of the steps (with full explanations of what is going on in each step), could you share it?


TL; DR

rookie at bioinformatics requests for help in building a pipeline, all help would be appreciated.

Thank you for your time
Liam_Gallagher
04-20-2018, 08:00 AM
Check this: http://ab.inf.uni-tuebingen.de/software/megan6/
It uses %%DIAMOND%% to align sequences, then %%MEGAN%% for the taxonomic analysis.
Hope it helps!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
21
http://seqanswers.com/forums/archive/index.php/t-81707.html
View Full Version : Number of reads in paired end fastq files
bong28
04-08-2018, 10:27 AM
I have two fastq files from paired end sequencing. I got those two files after converting a bam file to fastq. I was doing a quality check on the files, when I saw the number of sequences option in FASTQC tool gave different number for both files.
The number of sequences for read 1 was : 508168252
The number of sequences for read 2 was : 512336921

Shouldn't this be the same?
GenoMax
04-08-2018, 01:57 PM
Normally yes.

I suggest that you use use "repair.sh" from %%BBMap%% suite (https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/repair-guide/) to re-pair the reads and remove singletons to a separate file. Assuming your conversion has properly worked.
bong28
04-08-2018, 10:53 PM
Thanks for your reply
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
22
http://seqanswers.com/forums/archive/index.php/t-81679.html
View Full Version : Pooled sample for GWAS power
laurence_13
04-06-2018, 07:00 AM
Hi,

I'm very new to the forum, if you have any suggestions, please share them.

So i'm working with honey bee to identify QTL associated to a resistance trait (quantitative trait) using GWAS (by calling SNPs).
Honey bee queens are diploid and males progeniture inherit 1/2 of their genes (so they are haploid).
We want to sequence the queens, but can't use them, so we sampled the males progeny. I made 4 pools of 6 males for each queen.

My question is this: Is it better to do all my pipeline to SNP calling on each of the 4 pools individually before joining the results together, or should i joint the pools raw reads before starting my pipeline to enhance statistical power?

My logic is that if I don't initially joint them, I can later compare allele frequency between each replicate to insure that rare variants are not eliminated.

thanks
gringer
04-17-2018, 04:06 PM
My usual approach is to do the mapping separately, and do variant calling in parallel with %%samtools%% mpileup in multi-BAM mode (i.e. using more than one BAM file on the command line). This increases the chance that a rare/odd variant will be picked up, and makes sure that all variants are called in all samples.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
23
http://seqanswers.com/forums/archive/index.php/t-81581.html
View Full Version : gene expression profilling
dayana42200
04-02-2018, 03:07 AM
Hello everyone.

I have a questions on gene expression profiling.

1. Does the end product of gene expression profiling is in a DNA sequence? If so, does the sequence is in normal DNA sequence or mutated DNA sequence?
2. What are the method use to develop the expression profile?
3. Please share any related article of the method. Ive have search a lot on the method, but i cant understand since im not from bioinformatic background.
4. If anyone familiar with BRCA1 gene expression profiling, can anyone share with me the development of the profile?

Thank you for your time and reply.
GenoMax
04-02-2018, 04:28 AM
1. If you are doing RNAseq then yes you would sequence DNA that is derived from RNA. Unless you know beforehand the DNA being sequenced may be normal or mutated.
2. %%DESeq2%% , %%edgeR%% and %%LIMMA%% are some of the popular methods used for differential gene expression. They can also generate normalized data giving you a profile of gene expression.
3. Original concept came from microarrays. This link (https://www.genome.gov/10000533/dna-microarray-technology/)contains a basic introduction.
4. I am not sure what you referring to when you say profile. You can refer to this publication (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2667820/)for a set of 50 genes that was identified to predict risk/classify breast cancers.
dayana42200
04-04-2018, 07:07 PM
@GenoMax

Ive read the introduction of microarray. I dont really understand this statement.

"Both sets of labeled DNA are then inserted into the chip and allowed to hybridize - or bind - to the synthetic DNA on the chip.

If the individual does not have a mutation for the gene, both the red and green samples will bind to the sequences on the chip that represent the sequence without the mutation (the "normal" sequence).

If the individual does possess a mutation, the individual's DNA will not bind properly to the DNA sequences on the chip that represent the "normal" sequence but instead will bind to the sequence on the chip that represents the mutated DNA"

1. Synthetic DNA in the microarray, is the synthetic DNA is normal or mutated DNA or both?
2. Also for BRCA1 profile, I mean is a strand of DNA in a certain length that is able to detect BRCA1 gene.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
24
http://seqanswers.com/forums/archive/index.php/t-81560.html
View Full Version : NGS-Ig data
pablo12
03-31-2018, 07:47 AM
Dear users,

I'd like to ask you for your advise on a certain project that I am working on.

My job is to retrospectively analyse NGS data from patients suffering from ALL and MM (IGH).
However, I am not a bioinformatician. I just received the sequencing data in Excel (and .csv) files and I'm supposed to analyse these data.

Of course, I've heard of %%IMGT/VQUEST%% and %%IgBlast%% and it is no problem for me to work with these programmes. But the issue is that I can't do this with tens of thousands of sequences.

After further research, I came across the R tool tcR. It seems to be a well-done programme. Unfortunately, I always receive error messages when trying to integrate my files in it.

I found out that it might be useful to convert my files into .txt files or to work with VDJ-tools, Immunoseq, mixcr or other tools. But I do not have access to these programmes or they require Linux (which I don't have; Windows).

In addition, the sequencing data in my Excel files are not in fasta-format. But if I would change this by editing the sequences manually I'd be busy for the next three months.

My goal is to analyse my data for gene usage and to be able to search quickly for potential subclones.


I look forward to hearing your opinion! :)
Thanks in advance!

Pablo
colindaven
04-16-2018, 05:49 AM
You can probably use the sequences from the CSV files to create fasta files with a bit of creativity.

Have a look at good text editors like Notepad++ to get this done.

Also check out %%Galaxy%% for user friendly processing tools.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
25
http://seqanswers.com/forums/archive/index.php/t-81451.html
View Full Version : Microarray data (bedGraph) to metaplot.
rivered
03-26-2018, 01:00 PM
Hi all,

I am running into troubles with the microarray data I am trying to analyze. Lets try to explain this clearly. I have two sets of genes for which Iam trying to find differences in histone modifications. For most of the histone modifications, I was able to get pretty elaborate .bam files and making the metaplots was easy-peazy (attach3).

For some of the older data published, such as from microarray data, the process is less straight forward. I converted the microarray data to .bed files and after this to .bam files to analyze them with the R metagene package. For most .bam files this package works great. However because there is no read count available but only intensity the metaplot package does not give nice outputs.

Here is an example of the .bedgraph file used to make .bam (added a mockID)
chrnumber; start; end; normalized intensity
Chr1 25 50 0.005
Chr1 60 85 0.001
Chr1 113 138 0.001
Chr1 154 179 0.359
Chr1 185 210 0.001
Chr1 219 244 0.004
Chr1 254 279 4.599
Chr1 287 312 3.908

And this is how the .bam files look
id-1 0 Chr1 26 255 25M * 0 0 * *
id-2 0 Chr1 61 255 25M * 0 0 * *
id-3 0 Chr1 114 255 25M * 0 0 * *
id-4 0 Chr1 155 255 25M * 0 0 * *


I added an attachment to view the output from the metagene package. When I view these .bedgraph file in IGV for example the curves look really nice for the histone marks, compared to the .bam files generated from the .bedgraphs. This is most likely also the reason why the metagene package is not able to plot my data well.

I tried plotting the .bedGraphs with another package called metagene-maker but this program gives me IndexError: list index out of range. I think this error is caused because most of the reads are not in my designated .bed files with the regions of the genes I want to map. It would take quite some effort to do this manually and this is probably not the way to go. I was thinking about giving the .bam file some mock read count, and use the intensity as the mapping quality but most likely this is not a great idea from a bioinformatics view, and could give some problems upon publication.

I am just wondering what the way forward would be from a bioinformaticians view as other complete .bam files give beautifull output.

So summing it up; I have .bed, .bam and .bedGraph files from microarray data; location and intensity of predesigned probes mapped to genome. Want to know which is the best way to make metaplots of this data against .bed files with self-defined regions (in .bed format).

Help would be greatly appreciated!
R
colindaven
04-16-2018, 06:05 AM
Tricky. Perhaps its not possible.

However, you can do something similar I believe with deeptools (see the installation in the usegalaxy.eu server for example) if you convert from bedgraph to bigwig.

Thats a bit of a mission in itself, but java-genomics-toolkit can help you do that.

Best of luck
rivered
04-24-2018, 03:39 AM
Thank you for your reply. In the end I decided to use the bed files to make scorematrices with the library("genomation") package in R. These could be plotted with plotMeta function and statistics could be done with ks.test on colmeans from scorematrices.

%%Deeptools%% works as well but this would have been more effort. Good luck to anyone in the future struggling with this.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
26
http://seqanswers.com/forums/archive/index.php/t-81448.html
View Full Version : Question: counting after aligning miRNA reads to miRBase mature miRNA instead of refe
inah@bi.vt.edu
03-26-2018, 07:09 PM
I have human miRNA-seq data. In the past I have aligned these data using Bowtie2 to the reference genome (Homo_sapiens.GRCh38.dna.toplevel.fa), and I have subsequently performed counting using featureCounts with the annotation file hsa.gff3 from miRBase. . Now I have aligned the reads to the mature miRNA from miRBase (mature.fa), but when I look at the resulting bam files, the reads have a flag of 4 (segment unmapped) and there is no position information in mature.fa.

So can I use mature.fa as the reference for alignment and if so how is counting performed?

Thanks, Ina
sbarberan
03-26-2018, 11:39 PM
Hi Ina,

I use %samtools% and %picard-tools% to get the counts for miRNAs.

Here is what I would do for bowtie2 alignment to miRBase
bowtie2 -L8 --local -x miRBase-mature-hsa-index -U FILE.fastq -S FILE.sam
samtools view -b -S FILE.sam > FILE.bam
samtools sort FILE.bam > FILE.sorted
picard-tools BuildBamIndex I=FILE.sorted
picard-tools BamIndexStats I=FILE.sorted > FILE.txt

Makes sense?

Cheers,
sergio
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
27
http://seqanswers.com/forums/archive/index.php/t-81203.html
View Full Version : help for NGS and assembly
wanadou
03-14-2018, 09:29 AM
Hello

I think to do the whole genome sequencing of a halophyte plant (350 Mbp) using the Hiseq Pe150 which generate data with 30X coverage
1- this strategy could it be effective to make an de novo assembly in order to have a draft genome?
or
the sequencing using PacBio (1 cell SMRT) to generate sequences with more bigger size is it effective to make de novo assembly of the draft genome?
nucacidhunter
03-14-2018, 01:38 PM
The genome size is relatively small so you will have better assembly if you sequence with PacBio but one SMRT cell will not be enough. You should consider 50x coverage (17.5 Gb) which will require 3-4 Sequel SMRT cells. You can also sequence 2 SMRT cells and then do a preliminary assembly and decide on further sequencing.

Illumina sequencing will result in lots of short contigs especially if the plant genome is composed of repeat regions.

I do not think any of these platforms will enable complete assembly but the results will be better if DNA is from a homozygous plant.
wanadou
03-15-2018, 10:16 AM
Hello nucacidhunter,
Thanks for your reply
The cost of sequencing using PacBio is relatively high. the sequencing of 1 cell SMRT can give 5Gb. I think to do an preliminary assembly for a draft genome. In second time i will do sequencing using Illumina platform which provide 50X coverage. this second sequencing can be used to do hybrid assembly in ordre to have complete genome.
you think this strategy is feasible? or 10-15X coverage given by PacBio is insuffusant to do draft genome assembly
nucacidhunter
03-15-2018, 12:26 PM
It depends on the genome. You might look at repeat content of a related species if it is available. I have seen Illumina based assembled contigs which were couple of hundred bases larger than the sequencing length.

I do not think either of these platforms alone or in combination will give complete assembly but I would recommend to do 2 SMRT cells and assemble then depending on results decide for more sequencing on one. For instance, if you are interested in particular genes or region covered by PacBio contigs then Illumina will be good to increase accuracy. Depending on your application an incomplete assembly might be enough.

PacBio is sensitive to carry over of contaminants from DNA extraction so you should try an extraction method that result in long fragments and is free from carbohydrates and phenolic compounds. Link for PacBio calculator:
https://www.pacb.com/cn/calculator-whole-genome-sequencing/
colindaven
04-16-2018, 05:10 PM
Its' very tricky to analyse 10X pacbio data and do a de novo assembly. I have had very bad experiences in the past with this setup, getting poor N50s and putting lots of effort in. 30x+ is far, far better since you need a lot of the longest reads to span gaps AND self correct reads for a decent assembly .

There were a few tools for low coverage pacbio hybrid assembly, %DBG2OLC% for example
Markiyan
04-16-2018, 07:13 PM
Please use Illumina 2x250 or 2x300 in any de novo appication! (in addition to the pacbio).

It means 1-2 runs (2x250 or 2x300) using MiSeq or 1/2 of the HiSeq 2500 RR 2x250.

Usually it gives you significantly better assemblies than 2x150 or 2x100 bp runs.

PS: Make sure a PCR-free library prep is used.
gringer
04-18-2018, 03:37 AM
If you want cheap, [MinION](https://store.nanoporetech.com/basic.html) is always available (starter discount is $1000 for two flow cells and a rapid kit). The consensus assemblies are less accurate than PacBio, but if you're doing Illumina as well for local assembly correction (which I also recommend) that probably won't matter as much.
luc
04-21-2018, 03:16 AM
The sequencer is certainly cheap, but to my knowledge not the reagents and additional flowcells. PacBio might be more affordable?

If you want cheap, [MinION](https://store.nanoporetech.com/basic.html) is always available (starter discount is $1000 for two flow cells and a rapid kit). The consensus assemblies are less accurate than PacBio, but if you're doing Illumina as well for local assembly correction (which I also recommend) that probably won't matter as much.
gringer
04-21-2018, 03:25 AM
As far as I know, ONT is the only sequencing machine supplier that publishes all their prices on their store website; you can have a look and see for yourself!

At the moment marginal cost per base for the MinION is approximately equal to PacBio Sequel or Illumina MiSeq, with longer reads, a shorter sample preparation time, and no net capital expense for the sequencer. Flow cells are cheaper if ordered in bulk, and those who want the maximum affordability (and have lots of money to throw around) can purchase a PromethION.

Reminder: all those costs are on the ONT store website (https://store.nanoporetech.com/).
soungalo
04-22-2018, 01:46 PM
You won't be able to get a de novo assembly this way.
Regarding the Illumina strategy - to get a decent assembly you'll have to:
a. Increase coverage (50-60X should be OK)
b. Use longer reads (250bp), preferably use an insert size allowing for merging paired end reads.
c. Use various insert size libraries (for example by applying mate-pair technology).

As for PacBio - except for the simplest genomes, pure PacBio data cannot produce a decent assembly. Hybrid approaches are nice, but you'll still need lots of Illumina data, which means considerable costs.
gringer
04-22-2018, 02:00 PM
You won't be able to get a good de-novo assembly from Illumina data alone, and longer SBS reads won't fix that. Consider things like 28S rRNA gene regions, where kilobase-length regions are repeated many times in tandem; those will never be properly assembled from just Illumina data.

A hybrid approaches with reasonable long-read coverage (e.g. 40-100X) for generating assembly scaffolds and low short-read coverage (e.g. 40X) for local correction should produce somewhat contiguous sequences (e.g. N50 > 100 kb) that have a high accuracy. Contiguity can be improved with more long-range techniques like Hi-C and optical mapping.

Single-technology sequencing is (at the moment) a false economy. The additional money spent on hybrid sequencing approaches is more than made up for by the reduced pain on the bioinformatics end of things.
nucacidhunter
04-22-2018, 02:14 PM
As far as I know, ONT is the only sequencing machine supplier that publishes all their prices on their store website; you can have a look and see for yourself!
Reminder: all those costs are on the ONT store website (https://store.nanoporetech.com/).

This is because ONT sells their consumables directly but other companies such as PacBio sell them through a local distributor that have different margin and shipping costs depending on global location.

A 50-80x coverage with PacBio alone depending on genome heterogeneity results in very good assembly.
gringer
04-22-2018, 03:25 PM
other companies such as PacBio sell them through a local distributor that have different margin and shipping costs depending on global location.

That's not the only reason. Sigma also has region-specific pricing. Without logging in, I choose the location when I first visit the site (presumably stored as a cookie for subsequent visits), and their website gives me prices for items.
luc
04-23-2018, 01:16 AM
Final costs depend on reagent costs and yields (and reliability). Results for both systems will depend a lot on DNA sample quality. At current yields the Sequel runs will yield more data/dollar in our hands, if one is not ordering a pack of 48 or 300 nanopore flowcells. The average nanopore read lengths will be longer, but results/flowcells seem much more variable.

As far as I know, ONT is the only sequencing machine supplier that publishes all their prices on their store website; you can have a look and see for yourself!

At the moment marginal cost per base for the MinION is approximately equal to PacBio Sequel or Illumina MiSeq, with longer reads, a shorter sample preparation time, and no net capital expense for the sequencer. Flow cells are cheaper if ordered in bulk, and those who want the maximum affordability (and have lots of money to throw around) can purchase a PromethION.

Reminder: all those costs are on the ONT store website (https://store.nanoporetech.com/).
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
28




















